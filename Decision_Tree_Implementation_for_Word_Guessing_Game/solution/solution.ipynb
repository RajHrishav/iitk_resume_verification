{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1NC4VVrrWl0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "def my_fit( words, verbose = False ):\n",
        "\tdt = Tree( min_leaf_size = 1, max_depth = 15 )\n",
        "\tdt.fit( words, verbose )\n",
        "\treturn dt\n",
        "\n",
        "\n",
        "class Tree:\n",
        "\tdef __init__( self, min_leaf_size, max_depth ):\n",
        "\t\tself.root = None\n",
        "\t\tself.words = None\n",
        "\t\tself.min_leaf_size = min_leaf_size\n",
        "\t\tself.max_depth = max_depth\n",
        "\n",
        "\tdef fit( self, words, verbose = False ):\n",
        "\t\tself.words = words\n",
        "\t\tself.root = Node( depth = 0, parent = None )\n",
        "\t\tif verbose:\n",
        "\t\t\tprint( \"root\" )\n",
        "\t\t\tprint( \"└───\", end = '' )\n",
        "\t\t# The root is trained with all the words\n",
        "\t\tself.root.fit( all_words = self.words, my_words_idx = np.arange( len( self.words ) ), min_leaf_size = self.min_leaf_size, max_depth = self.max_depth, verbose = verbose )\n",
        "\n",
        "\n",
        "class Node:\n",
        "\t# A node stores its own depth (root = depth 0), a link to its parent\n",
        "\t# A link to all the words as well as the words that reached that node\n",
        "\t# A dictionary is used to store the children of a non-leaf node.\n",
        "\t# Each child is paired with the response that selects that child.\n",
        "\t# A node also stores the query-response history that led to that node\n",
        "\t# Note: my_words_idx only stores indices and not the words themselves\n",
        "\tdef __init__( self, depth, parent ):\n",
        "\t\tself.depth = depth\n",
        "\t\tself.parent = parent\n",
        "\t\tself.all_words = None\n",
        "\t\tself.my_words_idx = None\n",
        "\t\tself.children = {}\n",
        "\t\tself.is_leaf = True\n",
        "\t\tself.query_idx = None\n",
        "\t\tself.history = []\n",
        "\n",
        "\t# Each node must implement a get_query method that generates the\n",
        "\t# query that gets asked when we reach that node. Note that leaf nodes\n",
        "\t# also generate a query which is usually the final answer\n",
        "\tdef get_query( self ):\n",
        "\t\treturn self.query_idx\n",
        "\n",
        "\t# Each non-leaf node must implement a get_child method that takes a\n",
        "\t# response and selects one of the children based on that response\n",
        "\tdef get_child( self, response ):\n",
        "\t\t# This case should not arise if things are working properly\n",
        "\t\t# Cannot return a child if I am a leaf so return myself as a default action\n",
        "\t\tif self.is_leaf:\n",
        "\t\t\tprint( \"Why is a leaf node being asked to produce a child? Melbot should look into this!!\" )\n",
        "\t\t\tchild = self\n",
        "\t\telse:\n",
        "\t\t\t# This should ideally not happen. The node should ensure that all possibilities\n",
        "\t\t\t# are covered, e.g. by having a catch-all response. Fix the model if this happens\n",
        "\t\t\t# For now, hack things by modifying the response to one that exists in the dictionary\n",
        "\t\t\tif response not in self.children:\n",
        "\t\t\t\tprint( f\"Unknown response {response} -- need to fix the model\" )\n",
        "\t\t\t\tresponse = list(self.children.keys())[0]\n",
        "\n",
        "\t\t\tchild = self.children[ response ]\n",
        "\n",
        "\t\treturn child\n",
        "\n",
        "\t# Dummy leaf action -- just return the first word\n",
        "\tdef process_leaf( self, my_words_idx, history ):\n",
        "\t\t#while(any(q in sublist for sublist in history)):\n",
        "\t\t\t#q = np.random.randint( 0, len( my_words_idx ) )\n",
        "\t\tresponse = history[-1][1]\n",
        "\t\tresponse = response.replace(\" \", \"\")\n",
        "\t\tmatching_idx = []\n",
        "\t\tfor i in my_words_idx:\n",
        "\t\t\ttp = self.all_words[i]\n",
        "\t\t\tfoo = 0\n",
        "\t\t\tfor j in range(len(response)):\n",
        "\t\t\t\tif(response[j] == '_'):\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tif(not (response[j] == tp[j])):\n",
        "\t\t\t\t\t\tfoo = 1\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\tif(foo == 0):\n",
        "\t\t\t\tmatching_idx.append(i)\n",
        "\t\tq = np.random.randint( 0, len( matching_idx ) )\n",
        "\t\treturn matching_idx[q]\n",
        "\n",
        "\n",
        "\n",
        "\t\treturn q\n",
        "\t\t#return my_words_idx[0]\t\t\t\t# CHANGE THIS\n",
        "\n",
        "\tdef reveal( self, word, query ):\n",
        "\t\t# Find out the intersections between the query and the word\n",
        "\t\tmask = [ *( '_' * len( word ) ) ]\n",
        "\n",
        "\t\tfor i in range( min( len( word ), len( query ) ) ):\n",
        "\t\t\tif word[i] == query[i]:\n",
        "\t\t\t\tmask[i] = word[i]\n",
        "\n",
        "\t\treturn ' '.join( mask )\n",
        "\n",
        "\tdef try_maxig(self, all_words, my_words_idx, history):\n",
        "\t\tmaxig = -1\n",
        "\t\tfinal_index = -1\n",
        "\t\ttotal_words = len(my_words_idx)\n",
        "\t\tfor q in my_words_idx:\n",
        "\t\t\t#if (any(q in sublist for sublist in history)):\n",
        "\t\t\t\t#continue\n",
        "\t\t\tquery = all_words[q]\n",
        "\t\t\tsplit_dict = {}\n",
        "\t\t\tfor idx in my_words_idx:\n",
        "\t\t\t\tif(idx == q):\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tmask = self.reveal( all_words[ idx ], query )\n",
        "\t\t\t\tif mask not in split_dict:\n",
        "\t\t\t\t\tsplit_dict[ mask ] = []\n",
        "\n",
        "\t\t\t\tsplit_dict[ mask ].append( idx )\n",
        "\t\t\tsummig = 0\n",
        "\t\t\tfor i in split_dict:\n",
        "\t\t\t\tratio = (1.0 * len(split_dict[i])) / total_words\n",
        "\t\t\t\tsummig += ratio * math.log2(ratio)\n",
        "\t\t\tig = math.log2(total_words) - (summig)\n",
        "\t\t\tif (ig > maxig):\n",
        "\t\t\t\tmaxig = ig\n",
        "\t\t\t\tfinal_index = q\n",
        "\n",
        "\t\treturn final_index\n",
        "\n",
        "\n",
        "\t# Dummy node splitting action -- use a random word as query\n",
        "\t# Note that any word in the dictionary can be the query\n",
        "\tdef process_node( self, all_words, my_words_idx, history, verbose ):\n",
        "\t\t# For the root we do not ask any query -- Melbot simply gives us the length of the secret word\n",
        "\t\tif len( history ) == 0:\n",
        "\t\t\tquery_idx = -1\n",
        "\t\t\tquery = \"\"\n",
        "\t\telse:\n",
        "\t\t\t#query_idx = np.random.randint( 0, len( all_words ) )        #CHANGE THIS\n",
        "\t\t\tquery_idx = self.try_maxig(all_words, my_words_idx, history)\n",
        "\t\t\tquery = all_words[ query_idx ]\n",
        "\n",
        "\n",
        "\t\tsplit_dict = {}\n",
        "\t\tfor idx in my_words_idx:\n",
        "\t\t\tmask = self.reveal( all_words[ idx ], query )\n",
        "\t\t\tif mask not in split_dict:\n",
        "\t\t\t\tsplit_dict[ mask ] = []\n",
        "\n",
        "\t\t\tsplit_dict[ mask ].append( idx )\n",
        "\n",
        "\t\tif len( split_dict.items() ) < 2 and verbose:\n",
        "\t\t\tprint( \"Warning: did not make any meaningful split with this query!\" )\n",
        "\n",
        "\t\treturn ( query_idx, split_dict )\n",
        "\n",
        "\tdef fit( self, all_words, my_words_idx, min_leaf_size, max_depth, fmt_str = \"    \", verbose = False ):\n",
        "\t\tself.all_words = all_words\n",
        "\t\tself.my_words_idx = my_words_idx\n",
        "\n",
        "\t\t# If the node is too small or too deep, make it a leaf\n",
        "\t\t# In general, can also include purity considerations into account\n",
        "\t\tif len( my_words_idx ) <= min_leaf_size or self.depth >= max_depth:\n",
        "\t\t\tself.is_leaf = True\n",
        "\t\t\tself.query_idx = self.process_leaf( self.my_words_idx, self.history )\t\t\t# CHANGE THIS\n",
        "\t\t\tif verbose:\n",
        "\t\t\t\tprint( '█' )\n",
        "\t\telse:\n",
        "\t\t\tself.is_leaf = False\n",
        "\t\t\t( self.query_idx, split_dict ) = self.process_node( self.all_words, self.my_words_idx, self.history, verbose )\n",
        "\n",
        "\t\t\tif verbose:\n",
        "\t\t\t\tprint( all_words[ self.query_idx ] )\n",
        "\n",
        "\t\t\tfor ( i, ( response, split ) ) in enumerate( split_dict.items() ):\n",
        "\t\t\t\tif verbose:\n",
        "\t\t\t\t\tif i == len( split_dict ) - 1:\n",
        "\t\t\t\t\t\tprint( fmt_str + \"└───\", end = '' )\n",
        "\t\t\t\t\t\tfmt_str += \"    \"\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tprint( fmt_str + \"├───\", end = '' )\n",
        "\t\t\t\t\t\tfmt_str += \"│   \"\n",
        "\n",
        "\t\t\t\t# Create a new child for every split\n",
        "\t\t\t\tself.children[ response ] = Node( depth = self.depth + 1, parent = self )\n",
        "\t\t\t\thistory = self.history.copy()\n",
        "\t\t\t\thistory.append( [ self.query_idx, response ] )\n",
        "\t\t\t\tself.children[ response ].history = history\n",
        "\n",
        "\t\t\t\t# Recursively train this child node\n",
        "\t\t\t\tself.children[ response ].fit( self.all_words, split, min_leaf_size, max_depth, fmt_str, verbose )"
      ]
    }
  ]
}